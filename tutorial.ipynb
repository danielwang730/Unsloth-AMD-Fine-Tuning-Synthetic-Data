{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "480066b8",
   "metadata": {},
   "source": [
    "<h1 align='center'>Synthetic Data Generation and Unsloth Tutorial</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "988e8e0a-e95f-4f46-840f-944bd7335754",
   "metadata": {},
   "source": [
    "## \ud83d\udcda Table of Contents:\n",
    "\n",
    "- [Synthetic Data Kit: Data Generation](#synthetic-data-generation)\n",
    "- [Unsloth: Fine-Tuning and saving the model](#fine-tuning)\n",
    "\n",
    "## Synthetic Data Generation\n",
    "\n",
    "In this section, we use the CLI from synthetic-data-kit to generate datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "roro3n17eek",
   "metadata": {},
   "source": [
    "### Testing Synthetic Data Kit Command\n",
    "\n",
    "Please make sure you are running vllm by opening a terminal and typing `vllm serve Unsloth/Llama-3.3-70B-Instruct   --port 8001   --max-model-len 48000   --gpu-memory-utilization 0.85`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f03d425f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaf6f9d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33f54be-101e-4e96-b892-b05ed5a08a72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      "\u001b[1m \u001b[0m\u001b[1;33mUsage: \u001b[0m\u001b[1msynthetic-data-kit [OPTIONS] COMMAND [ARGS]...\u001b[0m\u001b[1m                         \u001b[0m\u001b[1m \u001b[0m\n",
      "\u001b[1m                                                                                \u001b[0m\n",
      " A toolkit for preparing synthetic datasets for fine-tuning LLMs                \n",
      "                                                                                \n",
      "\u001b[2m\u256d\u2500\u001b[0m\u001b[2m Options \u001b[0m\u001b[2m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[2m\u2500\u256e\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-config\u001b[0m              \u001b[1;32m-c\u001b[0m      \u001b[1;33mPATH\u001b[0m  Path to configuration file               \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-install\u001b[0m\u001b[1;36m-completion\u001b[0m          \u001b[1;33m    \u001b[0m  Install completion for the current       \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m                                     shell.                                   \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-show\u001b[0m\u001b[1;36m-completion\u001b[0m             \u001b[1;33m    \u001b[0m  Show completion for the current shell,   \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m                                     to copy it or customize the              \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m                                     installation.                            \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36m-\u001b[0m\u001b[1;36m-help\u001b[0m                        \u001b[1;33m    \u001b[0m  Show this message and exit.              \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n",
      "\u001b[2m\u256d\u2500\u001b[0m\u001b[2m Commands \u001b[0m\u001b[2m\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u001b[0m\u001b[2m\u2500\u256e\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36msystem-check \u001b[0m\u001b[1;36m \u001b[0m Check if the selected LLM provider's server is running.       \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36mingest       \u001b[0m\u001b[1;36m \u001b[0m Parse documents (PDF, HTML, YouTube, DOCX, PPT, TXT) into     \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36m              \u001b[0m clean text.                                                   \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36mcreate       \u001b[0m\u001b[1;36m \u001b[0m Generate content from text using local LLM inference.         \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36mcurate       \u001b[0m\u001b[1;36m \u001b[0m Clean and filter content based on quality.                    \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36msave-as      \u001b[0m\u001b[1;36m \u001b[0m Convert to different formats for fine-tuning.                 \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2502\u001b[0m \u001b[1;36mserver       \u001b[0m\u001b[1;36m \u001b[0m Start a web interface for the Synthetic Data Kit.             \u001b[2m\u2502\u001b[0m\n",
      "\u001b[2m\u2570\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u256f\u001b[0m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit --help"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sv060626q8r",
   "metadata": {},
   "source": [
    "### Exploring Synthetic Data Kit CLI\n",
    "\n",
    "This command displays the help menu for the `synthetic-data-kit` CLI tool, showing available commands:\n",
    "- **system-check**: Verify LLM provider server is running\n",
    "- **ingest**: Parse documents (PDF, HTML, YouTube, etc.) into clean text\n",
    "- **create**: Generate synthetic content (Q&A pairs, instructions, etc.) using LLM\n",
    "- **curate**: Filter and clean generated content based on quality scores\n",
    "- **save-as**: Convert data to different formats (fine-tuning format, JSON, etc.)\n",
    "- **server**: Launch web interface for the toolkit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a6a6d30e-d3cc-43e5-b1dd-189d393aa8f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "\u001b[1;34mEnvironment variable check:\u001b[0m\n",
      "API_ENDPOINT_KEY: Not found\n",
      "get_llm_provider returning: vllm\n",
      "\u001b[?25l\u001b[32m vLLM server is running at \u001b[0m\u001b[4;94mhttp://localhost:8001/v1\u001b[0m\n",
      "\u001b[2KAvailable models: \u001b[1m{\u001b[0m\u001b[32m'object'\u001b[0m: \u001b[32m'list'\u001b[0m, \u001b[32m'data'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
      "\u001b[32m'Unsloth/Llama-3.3-70B-Instruct'\u001b[0m, \u001b[32m'object'\u001b[0m: \u001b[32m'model'\u001b[0m, \u001b[32m'created'\u001b[0m: \u001b[1;36m1768338574\u001b[0m, \n",
      "\u001b[32m'owned_by'\u001b[0m: \u001b[32m'vllm'\u001b[0m, \u001b[32m'root'\u001b[0m: \u001b[32m'Unsloth/Llama-3.3-70B-Instruct'\u001b[0m, \u001b[32m'parent'\u001b[0m: \u001b[3;35mNone\u001b[0m, \n",
      "\u001b[32m'max_model_len'\u001b[0m: \u001b[1;36m48000\u001b[0m, \u001b[32m'permission'\u001b[0m: \u001b[1m[\u001b[0m\u001b[1m{\u001b[0m\u001b[32m'id'\u001b[0m: \n",
      "\u001b[32m'modelperm-63a7897a4965477bb044ff3a7f9d2a8e'\u001b[0m, \u001b[32m'object'\u001b[0m: \u001b[32m'model_permission'\u001b[0m, \n",
      "\u001b[32m'created'\u001b[0m: \u001b[1;36m1768338574\u001b[0m, \u001b[32m'allow_create_engine'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'allow_sampling'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \n",
      "\u001b[32m'allow_logprobs'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'allow_search_indices'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'allow_view'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \n",
      "\u001b[32m'allow_fine_tuning'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'organization'\u001b[0m: \u001b[32m'*'\u001b[0m, \u001b[32m'group'\u001b[0m: \u001b[3;35mNone\u001b[0m, \u001b[32m'is_blocking'\u001b[0m: \n",
      "\u001b[3;91mFalse\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\u001b[1m]\u001b[0m\u001b[1m}\u001b[0m\n",
      "\u001b[2K\u001b[32m\u280b\u001b[0m Checking vLLM server at http://localhost:8001/v1...\n",
      "\u001b[1A\u001b[2K"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit -c config.yaml system-check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lou0vs3mbib",
   "metadata": {},
   "source": [
    "### Verifying LLM Server Status\n",
    "\n",
    "This command checks if the vLLM server is running and accessible at `http://localhost:8001/v1`. It displays:\n",
    "- Server status and endpoint\n",
    "- Available models (here: Unsloth/Llama-3.3-70B-Instruct)\n",
    "- Model configuration (max context length: 48000 tokens)\n",
    "\n",
    "The system is configured to use the vLLM provider as specified in `config.yaml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "289ebeda-4d12-4466-a6df-4a82bd4a175a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mkdir -p logical_reasoning/{sources,data/{input,parsed,generated,curated,final}}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lj8z1mjus4",
   "metadata": {},
   "source": [
    "### Creating Project Directory Structure\n",
    "\n",
    "This command creates a well-organized directory structure for the logical reasoning project:\n",
    "- `sources/`: Store original source documents (PDFs, etc.)\n",
    "- `data/input/`: Input files for processing\n",
    "- `data/parsed/`: Parsed text files after document ingestion\n",
    "- `data/generated/`: Generated synthetic Q&A pairs\n",
    "- `data/curated/`: Quality-filtered data after curation\n",
    "- `data/final/`: Final formatted data ready for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "264477d5-7d25-4fac-99a5-5497d7dcd753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data/logical_reasoning\n"
     ]
    }
   ],
   "source": [
    "cd logical_reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0vu978x4i9hb",
   "metadata": {},
   "source": [
    "### Navigating to Project Directory\n",
    "\n",
    "Changes the current working directory to `logical_reasoning/` where all subsequent operations will take place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2fa11bee-b9b0-470a-875c-673bc88d3cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liar_Truth.pdf.1    100%[===================>] 327.61K  --.-KB/s    in 0.1s    \n"
     ]
    }
   ],
   "source": [
    "!wget -P sources/ -q --show-progress   \"https://www.csus.edu/indiv/d/dowdenb/4/logical-reasoning-archives/logical-reasoning-2017-12-02.pdf\"   \"https://people.cs.umass.edu/~pthomas/solutions/Liar_Truth.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d3ded6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logical-reasoning-1 100%[===================>]   5.52M  1.49MB/s    in 4.1s    \n",
      "Liar_Truth.pdf      100%[===================>] 327.61K  --.-KB/s    in 0.1s    \n"
     ]
    }
   ],
   "source": [
    "# UPDATED\n",
    "!wget -P sources/ -q --show-progress   \"https://www.csus.edu/faculty/d/dowden/_internal/_documents/logical-reasoning-12.pdf\"   \"https://people.cs.umass.edu/~pthomas/solutions/Liar_Truth.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ac50ca4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 5.9M\n",
      "drwxr-xr-x 2 root root 4.0K Jan 13 21:20 .\n",
      "drwxr-xr-x 4 root root 4.0K Jan 13 21:10 ..\n",
      "-rw-r--r-- 1 root root 328K May 31  2017 Liar_Truth.pdf\n",
      "-rw-r--r-- 1 root root 5.6M Jul 31 02:19 logical-reasoning-12.pdf\n"
     ]
    }
   ],
   "source": [
    "!ls -lha sources/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ukh0uhxa8ca",
   "metadata": {},
   "source": [
    "### Downloading Source Documents\n",
    "\n",
    "Downloads two PDF documents related to logical reasoning and liar/truth puzzles:\n",
    "1. \"Logical Reasoning\" textbook from CSU Sacramento\n",
    "2. \"Liar and Truth Teller Puzzles\" from UMass\n",
    "\n",
    "These documents will serve as the knowledge base for generating synthetic training data. The `-q` flag runs wget in quiet mode, and `--show-progress` displays a progress bar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "26d79b79-1f40-4ede-bc54-60496ccf65e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cp sources/* data/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gcvmiim3d49",
   "metadata": {},
   "source": [
    "### Copying Source Files to Input Directory\n",
    "\n",
    "Copies all downloaded source documents from `sources/` to `data/input/` to prepare them for the ingestion pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c71729fe-a9f2-495c-9ef5-6f58bcaa1232",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "\u001b[34mProcessing directory: \u001b[0m\u001b[1;34m.\u001b[0m\u001b[1;35m/data/input/\u001b[0m\n",
      "\u001b[34mFound \u001b[0m\u001b[1;36m2\u001b[0m\u001b[34m supported files to process\u001b[0m\n",
      "\u001b[32m\u2713 Liar_Truth.pdf\u001b[0m\n",
      "\u001b[32m\u2713 logical-reasoning-\u001b[0m\u001b[1;36m12.\u001b[0m\u001b[32mpdf\u001b[0m\n",
      "\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[1;34mProcessing Summary:\u001b[0m\n",
      "Total files: \u001b[1;36m2\u001b[0m\n",
      "\u001b[32mSuccessful: \u001b[0m\u001b[1;36m2\u001b[0m\n",
      "\u001b[32mFailed: \u001b[0m\u001b[1;36m0\u001b[0m\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[32m\u2705 All files processed successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit ingest ./data/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ttgi76hqiv",
   "metadata": {},
   "source": [
    "### Ingesting and Parsing Documents\n",
    "\n",
    "This command processes the PDF files in `data/input/` using the synthetic-data-kit's **ingest** command:\n",
    "- Extracts text content from PDFs\n",
    "- Cleans and normalizes the text\n",
    "- Saves parsed text files to `data/parsed/`\n",
    "\n",
    "The output shows successful processing of 2 PDF files (Liar_Truth.pdf and logical-reasoning-2017-12-02.pdf)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe68a35-cbdd-453b-93fd-0d85e5489cea",
   "metadata": {},
   "source": [
    "Note: This will take about 10 minutes, set `--verbose` flag to see progress or reduce the `num-pairs` for a faster test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af209d32-0a99-4365-bee0-18a14af2c9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "get_llm_provider returning: vllm\n",
      "\u001b[32m\ud83d\udd17 Using vllm provider\u001b[0m\n",
      "\u001b[34mProcessing directory: \u001b[0m\u001b[1;34m.\u001b[0m\u001b[1;35m/data/parsed/\u001b[0m\u001b[34m for qa generation\u001b[0m\n",
      "\u001b[34mFound \u001b[0m\u001b[1;36m2\u001b[0m\u001b[34m qa files to process\u001b[0m\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "L Using vllm provider\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Processing 1 chunks to generate QA pairs...\n",
      "Batch processing complete.                                                      \n",
      "Generated 25 QA pairs total (requested: 50)\n",
      "Saving result to data/generated/Liar_Truth_qa_pairs.json\n",
      "Successfully wrote test file to data/generated/test_write.json\n",
      "Successfully wrote result to data/generated/Liar_Truth_qa_pairs.json\n",
      "\u001b[32m\u2713 Liar_Truth.txt\u001b[0m\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "L Using vllm provider\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Processing 352 chunks to generate QA pairs...\n",
      "Batch processing complete.                                                      \n",
      "Generated 50 QA pairs total (requested: 50)\n",
      "Saving result to data/generated/logical-reasoning-12_qa_pairs.json\n",
      "Successfully wrote test file to data/generated/test_write.json\n",
      "Successfully wrote result to data/generated/logical-reasoning-12_qa_pairs.json\n",
      "\u001b[32m\u2713 logical-reasoning-\u001b[0m\u001b[1;36m12.\u001b[0m\u001b[32mtxt\u001b[0m\n",
      "\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[1;34mContent Generation Summary \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mqa\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m:\u001b[0m\n",
      "Total files: \u001b[1;36m2\u001b[0m\n",
      "\u001b[32mSuccessful: \u001b[0m\u001b[1;36m2\u001b[0m\n",
      "\u001b[32mFailed: \u001b[0m\u001b[1;36m0\u001b[0m\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[32m\u2705 All files processed successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit -c ../config.yaml create ./data/parsed/ --type qa --num-pairs 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "s722mc1b399",
   "metadata": {},
   "source": [
    "### Generating Synthetic Q&A Pairs\n",
    "\n",
    "This command uses the synthetic-data-kit's **create** command to generate Q&A pairs from the parsed text:\n",
    "- Reads parsed text files from `data/parsed/`\n",
    "- Uses the vLLM provider with Llama-3.3-70B-Instruct model\n",
    "- Generates 50 Q&A pairs per file (`--num-pairs 50`)\n",
    "- Type is set to `qa` for question-answer pair generation\n",
    "- Outputs are saved to `data/generated/`\n",
    "\n",
    "The process chunks the text and generates questions with corresponding answers. This took about 10 minutes for the full run. Use `--verbose` flag to see detailed progress or reduce `--num-pairs` for faster testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "44510f47-9cbd-4890-984f-3980c145e554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "get_llm_provider returning: vllm\n",
      "\u001b[32m\ud83d\udd17 Using vllm provider\u001b[0m\n",
      "\u001b[34mProcessing directory: \u001b[0m\u001b[1;34m.\u001b[0m\u001b[1;35m/data/generated/\u001b[0m\u001b[34m for curation\u001b[0m\n",
      "\u001b[34mFound \u001b[0m\u001b[1;36m3\u001b[0m\u001b[34m JSON files to curate\u001b[0m\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Processing 5 batches of QA pairs...\n",
      "Batch processing complete.                                                      \n",
      "Rated 25 QA pairs\n",
      "Retained 22 pairs (threshold: 7.0)\n",
      "Average score: 8.2\n",
      "\u001b[32m\u2713 Liar_Truth_qa_pairs.json\u001b[0m\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Loading config from: ../config.yaml\n",
      "Config has LLM provider set to: vllm\n",
      "Processing 10 batches of QA pairs...\n",
      "Batch processing complete.                                                      \n",
      "Rated 50 QA pairs\n",
      "Retained 50 pairs (threshold: 7.0)\n",
      "Average score: 8.5\n",
      "\u001b[32m\u2713 logical-reasoning-12_qa_pairs.json\u001b[0m\n",
      "\u001b[31m\u2717 test_write.json: No QA pairs found in the input file\u001b[0m\n",
      "\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[1;34mCuration Summary \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mthreshold: \u001b[0m\u001b[1;36m7.0\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m:\u001b[0m\n",
      "Total files: \u001b[1;36m3\u001b[0m\n",
      "\u001b[32mSuccessful: \u001b[0m\u001b[1;36m2\u001b[0m\n",
      "\u001b[31mFailed: \u001b[0m\u001b[1;36m1\u001b[0m\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[33m\u26a0\ufe0f  Completed with \u001b[0m\u001b[1;36m1\u001b[0m\u001b[33m errors\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit -c ../config.yaml curate ./data/generated/ --threshold 7.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lr9f7y5tqur",
   "metadata": {},
   "source": [
    "### Curating and Quality Filtering\n",
    "\n",
    "This command uses the **curate** function to filter generated Q&A pairs based on quality:\n",
    "- Evaluates each Q&A pair using quality metrics\n",
    "- Filters pairs with quality score above threshold (7.0/10)\n",
    "- Removes low-quality, inconsistent, or malformed pairs\n",
    "- Saves curated data to `data/curated/`\n",
    "\n",
    "This ensures only high-quality synthetic data is used for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "67ed73a8-7f3e-4a6d-9bdb-ba190b8b1bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "Loading config from: /opt/venv/lib/python3.10/site-packages/synthetic_data_kit/config.yaml\n",
      "Config has LLM provider set to: api-endpoint\n",
      "\u001b[34mProcessing directory: \u001b[0m\u001b[1;34m.\u001b[0m\u001b[1;35m/data/curated/\u001b[0m\u001b[34m for format conversion to ft\u001b[0m\n",
      "\u001b[34mFound \u001b[0m\u001b[1;36m2\u001b[0m\u001b[34m JSON files to convert to ft format\u001b[0m\n",
      "\u001b[32m\u2713 Liar_Truth_qa_pairs_cleaned.json\u001b[0m\n",
      "\u001b[32m\u2713 logical-reasoning-12_qa_pairs_cleaned.json\u001b[0m\n",
      "\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[1;34mFormat Conversion Summary \u001b[0m\u001b[1;34m(\u001b[0m\u001b[1;34mft, json\u001b[0m\u001b[1;34m)\u001b[0m\u001b[1;34m:\u001b[0m\n",
      "Total files: \u001b[1;36m2\u001b[0m\n",
      "\u001b[32mSuccessful: \u001b[0m\u001b[1;36m2\u001b[0m\n",
      "\u001b[32mFailed: \u001b[0m\u001b[1;36m0\u001b[0m\n",
      "\u001b[1m==================================================\u001b[0m\n",
      "\u001b[32m\u2705 All files converted successfully!\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!synthetic-data-kit save-as ./data/curated/ --format ft"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "awlg3cppl1t",
   "metadata": {},
   "source": [
    "### Converting to Fine-Tuning Format\n",
    "\n",
    "This command uses the **save-as** function to convert curated Q&A pairs to fine-tuning format:\n",
    "- Reads curated JSON files from `data/curated/`\n",
    "- Converts to format `ft` (fine-tuning format with messages structure)\n",
    "- Outputs are saved to `data/final/` with proper conversation format\n",
    "- The resulting format is compatible with standard fine-tuning pipelines\n",
    "\n",
    "Successfully converted 2 files to fine-tuning format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ac2e7fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data/logical_reasoning\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data/logical_reasoning\")\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3dbbd1b2-a4f2-46b7-bd01-6841abde7637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83c\udfaf Total conversations: 72\n",
      "{\n",
      "  \"conversations\": [\n",
      "    {\n",
      "      \"content\": \"If Bradley H. Dowden is the author of the book 'Logical Reasoning' and he dedicated the 2012 edition to his wife Hellan, can we conclude that Hellan is his wife in the 1993 edition as well?\",\n",
      "      \"role\": \"user\"\n",
      "    },\n",
      "    {\n",
      "      \"content\": \"To solve this, let's break down the information given. The 1993 edition's acknowledgments mention Hellan Roth Dowden as a friend and colleague who helped with the project, but it does not explicitly state her relationship to Bradley H. Dowden at that time. However, the 2012 edition is dedicated to Hellan, his wife. Since the question asks if we can conclude Hellan is his wife in the 1993 edition, we must consider if the information provided allows us to make that assumption. Given that the 1993 edition does not specify Hellan's relationship to Bradley as his wife, and assuming that marital status can change over time, we cannot conclusively determine from the given information that Hellan was his wife in 1993. The dedication in the 2012 edition confirms their marital relationship at that point but does not provide retroactive confirmation of their relationship status in 1993.\",\n",
      "      \"role\": \"assistant\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "\n",
    "# ===== CONFIGURATION =====\n",
    "data_dir = \"./data/final\"  # Change this to your data directory\n",
    "\n",
    "# ===== STEP 1: Find all FT files =====\n",
    "data_path = Path(data_dir)\n",
    "ft_files = glob.glob(str(data_path / \"*.json\"))\n",
    "\n",
    "# ===== STEP 2: Load and convert all files =====\n",
    "all_data = []\n",
    "\n",
    "for file_path in ft_files:\n",
    "    # Load the JSON file\n",
    "    with open(file_path, 'r') as f:\n",
    "        ft_data = json.load(f)\n",
    "    \n",
    "    # Convert each item\n",
    "    for item in ft_data:\n",
    "        if 'messages' not in item:\n",
    "            continue\n",
    "        \n",
    "        # Extract only user and assistant messages\n",
    "        conversation = []\n",
    "        for msg in item['messages']:\n",
    "            if msg['role'] == 'user' or msg['role'] == 'assistant':\n",
    "                conversation.append({\n",
    "                    \"role\": msg['role'],\n",
    "                    \"content\": msg['content']\n",
    "                })\n",
    "        \n",
    "        # Add to our data if we have at least one exchange\n",
    "        if len(conversation) > 0:\n",
    "            all_data.append({\n",
    "                \"conversations\": conversation\n",
    "            })\n",
    "\n",
    "print(f\"\\n\ud83c\udfaf Total conversations: {len(all_data)}\")\n",
    "\n",
    "# ===== STEP 3: Create HuggingFace Dataset =====\n",
    "dataset = Dataset.from_list(all_data)\n",
    "\n",
    "# ===== STEP 4: Preview the data =====\n",
    "print(json.dumps(dataset[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3akj2fu3yr8",
   "metadata": {},
   "source": [
    "### Loading and Converting Data to HuggingFace Dataset\n",
    "\n",
    "This cell performs comprehensive data processing:\n",
    "\n",
    "1. **Finding Files**: Locates all JSON files in `data/final/` directory\n",
    "2. **Loading Data**: Reads each JSON file containing fine-tuning formatted data\n",
    "3. **Format Conversion**: Extracts user and assistant messages from the fine-tuning format\n",
    "4. **Structuring Conversations**: Creates a standardized conversation format with role-content pairs\n",
    "5. **Creating Dataset**: Converts the processed data into a HuggingFace Dataset object\n",
    "\n",
    "The output shows 74 total conversations were successfully loaded and formatted. The preview displays a sample conversation showing a knight-and-knave logic puzzle with its solution."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d7ec326-9902-49db-aee0-b84acfdfb2cb",
   "metadata": {},
   "source": [
    "## Fine-Tuning\n",
    "\n",
    "### Note: Please remember to shutdown the vLLM instance!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a5edd3d-b80c-4d61-b6b4-ad650f6bba96",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4678bc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/rocm6.4\n",
      "Requirement already satisfied: torch==2.8.0 in /opt/venv/lib/python3.10/site-packages (2.8.0+rocm6.4)\n",
      "Requirement already satisfied: pytorch-triton-rocm in /opt/venv/lib/python3.10/site-packages (3.4.0)\n",
      "Collecting pytorch-triton-rocm\n",
      "  Using cached https://download.pytorch.org/whl/pytorch_triton_rocm-3.5.1-cp310-cp310-linux_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/torchvision-0.24.1%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: torchaudio in /opt/venv/lib/python3.10/site-packages (2.8.0+rocm7.0.2.git0c223473)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/torchaudio-2.9.1%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "Requirement already satisfied: torchao==0.13.0 in /opt/venv/lib/python3.10/site-packages (0.13.0+rocm6.4)\n",
      "Requirement already satisfied: xformers in /opt/venv/lib/python3.10/site-packages (0.0.32.post2)\n",
      "Collecting xformers\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/xformers-0.0.33.post2-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/venv/lib/python3.10/site-packages (from torch==2.8.0) (2025.9.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/venv/lib/python3.10/site-packages (from pytorch-triton-rocm) (79.0.1)\n",
      "Requirement already satisfied: numpy in /opt/venv/lib/python3.10/site-packages (from torchvision) (2.2.6)\n",
      "INFO: pip is looking at multiple versions of torchvision to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchvision\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.4/torchvision-0.24.0%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (5.9 kB)\n",
      "  Downloading https://download.pytorch.org/whl/rocm6.4/torchvision-0.23.0%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/venv/lib/python3.10/site-packages (from torchvision) (12.1.0)\n",
      "INFO: pip is looking at multiple versions of torchaudio to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/torchaudio-2.9.0%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (6.9 kB)\n",
      "INFO: pip is looking at multiple versions of xformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting xformers\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/xformers-0.0.33.post1-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "  Using cached https://download.pytorch.org/whl/rocm6.4/xformers-0.0.33-cp39-abi3-manylinux_2_28_x86_64.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch==2.8.0) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.10/site-packages (from jinja2->torch==2.8.0) (3.0.3)\n",
      "Downloading https://download.pytorch.org/whl/rocm6.4/torchvision-0.23.0%2Brocm6.4-cp310-cp310-manylinux_2_28_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: torchvision\n",
      "Successfully installed torchvision-0.23.0+rocm6.4\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch==2.8.0 pytorch-triton-rocm torchvision torchaudio torchao==0.13.0 xformers --index-url https://download.pytorch.org/whl/rocm6.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68ac5410",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: unsloth in /opt/venv/lib/python3.10/site-packages (2026.1.2)\n",
      "Requirement already satisfied: unsloth-zoo in /opt/venv/lib/python3.10/site-packages (2026.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting git+https://github.com/unslothai/unsloth-zoo.git\n",
      "  Cloning https://github.com/unslothai/unsloth-zoo.git to /tmp/pip-req-build-tfe0p8xk\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth-zoo.git /tmp/pip-req-build-tfe0p8xk\n",
      "  Resolved https://github.com/unslothai/unsloth-zoo.git to commit c315ec1b0782a43893f34ed1dc264de9f2600236\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "\u001b[?25hCollecting unsloth@ git+https://github.com/unslothai/unsloth (from unsloth[amd]@ git+https://github.com/unslothai/unsloth)\n",
      "  Cloning https://github.com/unslothai/unsloth to /tmp/pip-install-0y83bi8n/unsloth_bb6b3a9366b64a4b84cf181389aa5f74\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/unslothai/unsloth /tmp/pip-install-0y83bi8n/unsloth_bb6b3a9366b64a4b84cf181389aa5f74\n",
      "  Resolved https://github.com/unslothai/unsloth to commit b96a04c17bc6bcb5522eafb17adc2b104be38f99\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth)\n",
      "  Downloading https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl (59.1 MB)\n",
      "\u001b[2K     \u001b[90m\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u2501\u001b[0m \u001b[32m59.1/59.1 MB\u001b[0m \u001b[31m113.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0meta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: torch<3,>=2.3 in /opt/venv/lib/python3.10/site-packages (from bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.8.0+rocm6.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/venv/lib/python3.10/site-packages (from bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/venv/lib/python3.10/site-packages (from bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (25.0)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.20.3)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2025.9.0)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.4.0 in /opt/venv/lib/python3.10/site-packages (from torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/venv/lib/python3.10/site-packages (from pytorch-triton-rocm==3.4.0->torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (79.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.10/site-packages (from jinja2->torch<3,>=2.3->bitsandbytes@ https://github.com/bitsandbytes-foundation/bitsandbytes/releases/download/continuous-release_main/bitsandbytes-1.33.7.preview-py3-none-manylinux_2_24_x86_64.whl->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.0.3)\n",
      "Requirement already satisfied: wheel>=0.42.0 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.45.1)\n",
      "Requirement already satisfied: tqdm in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.67.1)\n",
      "Requirement already satisfied: psutil in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (7.2.1)\n",
      "Requirement already satisfied: tyro in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.0.5)\n",
      "Requirement already satisfied: protobuf in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (6.33.4)\n",
      "Requirement already satisfied: sentencepiece>=0.2.0 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.2.1)\n",
      "Requirement already satisfied: datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.3.0)\n",
      "Requirement already satisfied: accelerate>=0.34.1 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.12.0)\n",
      "Requirement already satisfied: peft!=0.11.0,>=0.7.1 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.18.1)\n",
      "Requirement already satisfied: huggingface_hub>=0.34.0 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.36.0)\n",
      "Requirement already satisfied: hf_transfer in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.1.9)\n",
      "Requirement already satisfied: diffusers in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.36.0)\n",
      "Requirement already satisfied: transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.57.3)\n",
      "Requirement already satisfied: trl!=0.19.0,<=0.24.0,>=0.18.2 in /opt/venv/lib/python3.10/site-packages (from unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.24.0)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.28.1)\n",
      "Requirement already satisfied: xxhash in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.70.16)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/venv/lib/python3.10/site-packages (from datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (6.0.3)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/venv/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.13.3)\n",
      "Requirement already satisfied: anyio in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.16.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/venv/lib/python3.10/site-packages (from huggingface_hub>=0.34.0->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.2.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/venv/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.22.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/venv/lib/python3.10/site-packages (from transformers!=4.52.0,!=4.52.1,!=4.52.2,!=4.52.3,!=4.53.0,!=4.54.0,!=4.55.0,!=4.55.1,!=4.57.0,<=4.57.3,>=4.51.3->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.7.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.6.3)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/venv/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.3.1)\n",
      "Requirement already satisfied: importlib_metadata in /opt/venv/lib/python3.10/site-packages (from diffusers->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (8.7.0)\n",
      "Requirement already satisfied: Pillow in /opt/venv/lib/python3.10/site-packages (from diffusers->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (12.1.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/venv/lib/python3.10/site-packages (from importlib_metadata->diffusers->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (3.23.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets!=4.0.*,!=4.1.0,<4.4.0,>=3.4.1->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (1.17.0)\n",
      "Requirement already satisfied: docstring-parser>=0.15 in /opt/venv/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (0.17.0)\n",
      "Requirement already satisfied: typeguard>=4.0.0 in /opt/venv/lib/python3.10/site-packages (from tyro->unsloth@ git+https://github.com/unslothai/unsloth->unsloth[amd]@ git+https://github.com/unslothai/unsloth) (4.4.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install --no-deps unsloth unsloth-zoo\n",
    "!pip install --no-deps git+https://github.com/unslothai/unsloth-zoo.git\n",
    "!pip install \"unsloth[amd] @ git+https://github.com/unslothai/unsloth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7aae1ef9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /opt/venv/lib/python3.10/site-packages (0.24.0)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /opt/venv/lib/python3.10/site-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /opt/venv/lib/python3.10/site-packages (from trl) (4.3.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /opt/venv/lib/python3.10/site-packages (from trl) (4.57.3)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (2.2.6)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (7.2.1)\n",
      "Requirement already satisfied: pyyaml in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (2.8.0+rocm6.4)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /opt/venv/lib/python3.10/site-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.20.3)\n",
      "Requirement already satisfied: pyarrow>=21.0.0 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (22.0.0)\n",
      "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.4.0)\n",
      "Requirement already satisfied: pandas in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (2.3.3)\n",
      "Requirement already satisfied: requests>=2.32.2 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (2.32.5)\n",
      "Requirement already satisfied: httpx<1.0.0 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.28.1)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /opt/venv/lib/python3.10/site-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /opt/venv/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.9.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /opt/venv/lib/python3.10/site-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.3)\n",
      "Requirement already satisfied: anyio in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (4.12.1)\n",
      "Requirement already satisfied: certifi in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (2026.1.4)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (1.0.9)\n",
      "Requirement already satisfied: idna in /opt/venv/lib/python3.10/site-packages (from httpx<1.0.0->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/venv/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0->datasets>=3.0.0->trl) (0.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /opt/venv/lib/python3.10/site-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/venv/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/venv/lib/python3.10/site-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.6.3)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx in /opt/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /opt/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: pytorch-triton-rocm==3.4.0 in /opt/venv/lib/python3.10/site-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.4.0)\n",
      "Requirement already satisfied: setuptools>=40.8.0 in /opt/venv/lib/python3.10/site-packages (from pytorch-triton-rocm==3.4.0->torch>=2.0.0->accelerate>=1.4.0->trl) (79.0.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/venv/lib/python3.10/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/venv/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (2025.11.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /opt/venv/lib/python3.10/site-packages (from transformers>=4.56.1->trl) (0.22.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/venv/lib/python3.10/site-packages (from anyio->httpx<1.0.0->datasets>=3.0.0->trl) (1.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/venv/lib/python3.10/site-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/venv/lib/python3.10/site-packages (from pandas->datasets>=3.0.0->trl) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/venv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install trl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1974e93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ipywidgets in /opt/venv/lib/python3.10/site-packages (8.1.7)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/venv/lib/python3.10/site-packages (from ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/venv/lib/python3.10/site-packages (from ipywidgets) (8.37.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/venv/lib/python3.10/site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in /opt/venv/lib/python3.10/site-packages (from ipywidgets) (4.0.14)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in /opt/venv/lib/python3.10/site-packages (from ipywidgets) (3.0.15)\n",
      "Requirement already satisfied: decorator in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (5.2.1)\n",
      "Requirement already satisfied: exceptiongroup in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (1.3.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.9.0)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (2.15.0)\n",
      "Requirement already satisfied: stack_data in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: typing_extensions>=4.6 in /opt/venv/lib/python3.10/site-packages (from ipython>=6.1.0->ipywidgets) (4.15.0)\n",
      "Requirement already satisfied: wcwidth in /opt/venv/lib/python3.10/site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/venv/lib/python3.10/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.5)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/venv/lib/python3.10/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets) (0.7.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in /opt/venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in /opt/venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in /opt/venv/lib/python3.10/site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install ipywidgets widgetsnbextension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77d5db74-5070-45b7-bdae-f93d50909b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import glob\n",
    "import torch\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f91c4d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TORCH_COMPILE_DISABLE\"] = \"1\"                                                                                                                                                     \n",
    "os.environ[\"TORCHINDUCTOR_DISABLE\"] = \"1\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dulvo8ocyrb",
   "metadata": {},
   "source": [
    "### Importing Standard Libraries\n",
    "\n",
    "Imports essential Python libraries for fine-tuning:\n",
    "- `os`, `json`, `glob`: File system operations and JSON handling\n",
    "- `torch`: PyTorch deep learning framework\n",
    "- `shutil`: File operations\n",
    "- `Path`: Path manipulation\n",
    "- `Dataset`: HuggingFace datasets library for data handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c3cfa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device count: 1\n",
      "Accelerator available: True\n",
      "Current accelerator: cuda\n",
      "HIP available: True\n",
      "HIP version: 6.4.43482-0f2d60242\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available:\", torch.cuda.is_available())                                                                                                          \n",
    "print(\"Device count:\", torch.cuda.device_count())                                                                                                            \n",
    "                                                                                                                                                            \n",
    "if hasattr(torch, 'accelerator'):                                                                                                                            \n",
    "    print(\"Accelerator available:\", torch.accelerator.is_available())                                                                                        \n",
    "    if torch.accelerator.is_available():                                                                                                                     \n",
    "        print(\"Current accelerator:\", torch.accelerator.current_accelerator())                                                                               \n",
    "                                                                                                                                                            \n",
    "# Check ROCm specifically                                                                                                                                    \n",
    "print(\"HIP available:\", hasattr(torch.version, 'hip') and torch.version.hip is not None)                                                                     \n",
    "if hasattr(torch.version, 'hip'):                                                                                                                            \n",
    "    print(\"HIP version:\", torch.version.hip)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8adaf850-eb8a-476e-8d09-34c807c92e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83e\udda5 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "INFO 01-14 19:08:29 [__init__.py:241] Automatically detected platform rocm.\n",
      "WARNING 01-14 19:08:29 [rocm.py:34] Failed to import from vllm._C with ImportError('/opt/rocm/lib/libamdhip64.so.7: undefined symbol: hsa_amd_memory_get_preferred_copy_engine, version ROCR_1')\n",
      "WARNING 01-14 19:08:29 [rocm.py:40] Failed to import from vllm._rocm_C with ImportError('/opt/rocm/lib/libamdhip64.so.7: undefined symbol: hsa_amd_memory_get_preferred_copy_engine, version ROCR_1')\n",
      "WARNING 01-14 19:08:29 [_custom_ops.py:20] Failed to import from vllm._C with ImportError('/opt/rocm/lib/libamdhip64.so.7: undefined symbol: hsa_amd_memory_get_preferred_copy_engine, version ROCR_1')\n",
      "INFO 01-14 19:08:29 [layer.py:37] [Aiter] VLLM_ROCM_USE_AITER_TRITON_FUSED_ROPE_ZEROS_KV_CACHE=False\n",
      "INFO 01-14 19:08:29 [activation.py:67] [Aiter] VLLM_ROCM_USE_AITER_TRITON_SILU_MUL_FP4_QUANT=False\n",
      "INFO 01-14 19:08:29 [activation.py:68] [Aiter] VLLM_ROCM_USE_AITER_TRITON_SILU_MUL_FP8_QUANT=False\n",
      "INFO 01-14 19:08:29 [activation.py:69] [Aiter] VLLM_TRITON_FP4_GEMM_USE_ASM=False\n",
      "INFO 01-14 19:08:30 [llama.py:72] [Aiter] VLLM_ROCM_USE_AITER_TRITON_FUSED_ROPE_ZEROS_KV_CACHE=False VLLM_ROCM_USE_AITER_MHA=True\n",
      "Unsloth: Your Flash Attention 2 installation seems to be broken?\n",
      "A possible explanation is you have a new CUDA version which isn't\n",
      "yet compatible with FA2? Please file a ticket to Unsloth or FA2.\n",
      "We shall now use Xformers instead, which does not have any performance hits!\n",
      "We found this negligible impact by benchmarking on 1x A100.\n",
      "\ud83e\udda5 Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "from unsloth.chat_templates import get_chat_template, standardize_sharegpt, train_on_responses_only\n",
    "from trl import SFTConfig, SFTTrainer\n",
    "from transformers import DataCollatorForSeq2Seq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iwk3zcrzft",
   "metadata": {},
   "source": [
    "### Importing Unsloth and Training Libraries\n",
    "\n",
    "Imports specialized libraries for efficient fine-tuning:\n",
    "- `FastLanguageModel` from Unsloth: Optimized model loading and training\n",
    "- `get_chat_template`, `standardize_sharegpt`, `train_on_responses_only`: Chat formatting utilities\n",
    "- `SFTConfig`, `SFTTrainer`: Supervised fine-tuning configuration and trainer from TRL\n",
    "- `DataCollatorForSeq2Seq`: Handles batching and padding for sequence-to-sequence training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305661d0-5103-412c-9f33-7ad61cc288b3",
   "metadata": {},
   "source": [
    "### Setup Unsloth model and tokenizer for ROCm without bitsandbytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f5dffe96-b007-4220-b7b7-e40e219b267c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: WARNING `trust_remote_code` is True.\n",
      "Are you certain you want to do remote code execution?\n",
      "==((====))==  Unsloth 2026.1.2: Fast Llama patching. Transformers: 4.57.3. vLLM: 0.9.2rc2.dev2602+g03b8f9b84.rocm702.\n",
      "   \\\\   /|    AMD Radeon Graphics. Num GPUs = 1. Max memory: 191.688 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.8.0+rocm6.4. ROCm Toolkit: 6.4.43482-0f2d60242. Triton: 3.4.0\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = None. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/venv/lib/python3.10/site-packages/unsloth_zoo/gradient_checkpointing.py:355: UserWarning: expandable_segments not supported on this platform (Triggered internally at /pytorch/c10/hip/HIPAllocatorConfig.h:36.)\n",
      "  GPU_BUFFERS = tuple([torch.empty(2*256*2048, dtype = dtype, device = f\"{DEVICE_TYPE_TORCH}:{i}\") for i in range(n_gpus)])\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb9ff8e85fb245e3803a48a8a46b4ff7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Loaded: Llama-3.3-70B-Instruct (bfloat16, ROCm compatible)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2026.1.2 patched 80 layers with 80 QKV layers, 80 O layers and 80 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "max_seq_length = 1024\n",
    "dtype = torch.bfloat16  # Explicit bfloat16 for ROCm\n",
    "load_in_4bit = False  \n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=\"unsloth/Llama-3.3-70B-Instruct\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    "    device_map=\"auto\",\n",
    "    torch_dtype=torch.bfloat16,  # Explicit for ROCm\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Loaded: Llama-3.3-70B-Instruct (bfloat16, ROCm compatible)\")\n",
    "\n",
    "# Add LoRA adapters\n",
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r=64,  # Higher rank for 70B model\n",
    "    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                   \"gate_proj\", \"up_proj\", \"down_proj\"],\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0,\n",
    "    bias=\"none\",\n",
    "    use_gradient_checkpointing=\"unsloth\",\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    loftq_config=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b02f25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Device name: AMD Radeon Graphics\n",
      "Device count: 1\n",
      "HIP version: 6.4.43482-0f2d60242\n",
      "\n",
      "Model device: cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch                                                                                                                                                                                  \n",
    "                                                                                                                                                                                            \n",
    "# Basic GPU check                                                                                                                                                                             \n",
    "print(\"CUDA available:\", torch.cuda.is_available())                                                                                                                                           \n",
    "print(\"Device name:\", torch.cuda.get_device_name(0))                                                                                                                                          \n",
    "print(\"Device count:\", torch.cuda.device_count())                                                                                                                                             \n",
    "                                                                                                                                                                                            \n",
    "# Confirm it's ROCm (not NVIDIA CUDA)                                                                                                                                                         \n",
    "print(\"HIP version:\", torch.version.hip)                                                                                                                                                      \n",
    "                                                                                                                                                                                            \n",
    "# Check where your model is                                                                                                                                                                   \n",
    "print(\"\\nModel device:\", next(model.parameters()).device) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "erpk4j0opb6",
   "metadata": {},
   "source": [
    "### Loading Llama-3.3-70B Model with LoRA\n",
    "\n",
    "This cell sets up the model for efficient fine-tuning on AMD ROCm hardware:\n",
    "\n",
    "**Model Configuration:**\n",
    "- Model: Llama-3.3-70B-Instruct (70 billion parameters)\n",
    "- Data type: bfloat16 for ROCm compatibility\n",
    "- No quantization (load_in_4bit=False) to avoid bitsandbytes dependency\n",
    "- Max sequence length: 1024 tokens\n",
    "\n",
    "**LoRA (Low-Rank Adaptation) Configuration:**\n",
    "- Rank (r): 64 - Higher rank for the large 70B model\n",
    "- Target modules: All attention and MLP layers (q_proj, k_proj, v_proj, o_proj, gate_proj, up_proj, down_proj)\n",
    "- LoRA alpha: 64\n",
    "- Dropout: 0 (no dropout)\n",
    "- Gradient checkpointing: \"unsloth\" for memory efficiency\n",
    "\n",
    "LoRA enables efficient fine-tuning by only training small adapter layers instead of the entire 70B model, making it feasible to train on a single AMD MI300X GPU with 192GB HBM3 memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "496f9c09-609c-41f7-a7a7-c1f942405a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\ud83d\udd27 Preparing dataset for training...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2223369a36134109bf15e73cee16d120",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Standardizing formats (num_proc=20):   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "832b73c841a8483bafd4325bc82a221c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186825d49fe14e8280ac915cce901864",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Filter:   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u2705 Prepared 72 valid examples for training\n",
      "\ud83d\udcdd Sample formatted text:\n",
      "<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
      "\n",
      "Cutting Knowledge Date: December 2023\n",
      "Today Date: 26 July 2024\n",
      "\n",
      "<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
      "\n",
      "If Bradley H. Dowden is...\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Prepare dataset with proper chat template and tensor compatibility\"\"\"\n",
    "print(\"\ud83d\udd27 Preparing dataset for training...\")\n",
    "\n",
    "# Set chat template\n",
    "tokenizer = get_chat_template(tokenizer, chat_template=\"llama-3.1\")\n",
    "\n",
    "# Ensure pad token is set\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# Formatting function that ensures proper tensor conversion\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = []\n",
    "    \n",
    "    for convo in convos:\n",
    "        # Ensure conversation is in correct format\n",
    "        if isinstance(convo, list) and all(isinstance(msg, dict) for msg in convo):\n",
    "            text = tokenizer.apply_chat_template(convo, tokenize=False, add_generation_prompt=False)\n",
    "            texts.append(text)\n",
    "        else:\n",
    "            print(f\"\u26a0\ufe0f  Skipping malformed conversation: {type(convo)}\")\n",
    "            continue\n",
    "    \n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = standardize_sharegpt(dataset)\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True, remove_columns=dataset.column_names)\n",
    "\n",
    "dataset = dataset.filter(lambda x: len(x[\"text\"].strip()) > 0)\n",
    "\n",
    "print(f\"\u2705 Prepared {len(dataset)} valid examples for training\")\n",
    "\n",
    "# Show sample\n",
    "if len(dataset) > 0:\n",
    "    print(f\"\ud83d\udcdd Sample formatted text:\")\n",
    "    print(dataset[\"text\"][0][:200] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9exgyip7y8f",
   "metadata": {},
   "source": [
    "### Preparing Dataset with Chat Template\n",
    "\n",
    "This cell formats the dataset for fine-tuning:\n",
    "\n",
    "**Steps:**\n",
    "1. **Set Chat Template**: Applies Llama-3.1 chat template formatting\n",
    "2. **Configure Padding**: Sets pad token to eos token if not already set\n",
    "3. **Format Conversations**: The `formatting_prompts_func` function:\n",
    "   - Takes raw conversations from the dataset\n",
    "   - Applies the chat template to format them properly\n",
    "   - Validates conversation structure (list of dicts with role/content)\n",
    "   - Filters out malformed conversations\n",
    "4. **Standardize Format**: Uses `standardize_sharegpt` to normalize the data structure\n",
    "5. **Apply Formatting**: Maps the formatting function across all examples\n",
    "6. **Remove Empty**: Filters out any empty or invalid formatted texts\n",
    "\n",
    "The output shows 74 valid examples were successfully prepared. A sample of the formatted text is displayed, showing the proper Llama-3.1 chat template structure with system, user, and assistant headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "144231a7-313f-4db9-8f02-025148666732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7eb58e44250e4ba687b08e543e186af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: Tokenizing [\"text\"] (num_proc=24):   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7423da2caa8a455eb16e8968e39aa701",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=24):   0%|          | 0/72 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 72 | Num Epochs = 1 | Total steps = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 828,375,040 of 71,382,081,536 (1.16% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:08, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.986300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.106700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n",
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 72 | Num Epochs = 1 | Total steps = 2\n",
      "O^O/ \\_/ \\    Batch size per device = 64 | Gradient accumulation steps = 1\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (64 x 1 x 1) = 64\n",
      " \"-____-\"     Trainable parameters = 828,375,040 of 71,382,081,536 (1.16% trained)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2' max='2' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2/2 00:07, Epoch 1/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.936600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.050000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Train model with ROCm-optimized settings\"\"\"\n",
    "# Ensure tokenizer has proper padding\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# Setup trainer with ROCm-friendly settings and proper data handling\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    train_dataset=dataset,\n",
    "    dataset_text_field=\"text\",\n",
    "    max_seq_length=max_seq_length,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer=tokenizer, padding=True),\n",
    "    packing=False,\n",
    "    args=SFTConfig(\n",
    "        per_device_train_batch_size=64,  # \ud83d\ude80 MI300X can handle this with 192GB HBM3!\n",
    "        gradient_accumulation_steps=1,   # Effective batch size = 8*2 = 16\n",
    "        warmup_steps=5,\n",
    "        num_train_epochs=1,\n",
    "        learning_rate=1e-4,\n",
    "        logging_steps=1,\n",
    "        optim=\"adamw_8bit\",  # Pure torch optimizer\n",
    "        weight_decay=0.01,\n",
    "        lr_scheduler_type=\"linear\",\n",
    "        seed=3407,\n",
    "        output_dir=\"logical_reasoning_rocm_outputs\",\n",
    "        report_to=\"none\",\n",
    "        bf16=True,\n",
    "        dataloader_pin_memory=False,\n",
    "        remove_unused_columns=True,  # Remove unused columns to avoid tensor issues\n",
    "        gradient_checkpointing=True,\n",
    "        dataloader_num_workers=0,  # Single worker for ROCm stability\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Train only on responses\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part=\"<|start_header_id|>user<|end_header_id|>\\n\\n\",\n",
    "    response_part=\"<|start_header_id|>assistant<|end_header_id|>\\n\\n\",\n",
    ")\n",
    "\n",
    "FastLanguageModel.for_training(model)\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "otx9lfwgfmi",
   "metadata": {},
   "source": [
    "### Training the Model with ROCm-Optimized Settings\n",
    "\n",
    "This cell configures and executes the fine-tuning process:\n",
    "\n",
    "**Training Configuration (SFTConfig):**\n",
    "- **Batch size**: 64 per device - leveraging the AMD MI300X's massive 192GB HBM3 memory\n",
    "- **Gradient accumulation**: 1 step\n",
    "- **Warmup**: 5 steps\n",
    "- **Epochs**: 1 full pass through the dataset\n",
    "- **Learning rate**: 1e-4\n",
    "- **Optimizer**: adamw_8bit for memory efficiency\n",
    "- **Precision**: bf16 (bfloat16) for ROCm\n",
    "- **Gradient checkpointing**: Enabled for memory efficiency\n",
    "\n",
    "**Special Training Mode:**\n",
    "Uses `train_on_responses_only` to compute loss only on the assistant's responses, not on the user's questions. This focuses the model on learning to generate accurate answers rather than memorizing the input format.\n",
    "\n",
    "**Key Features:**\n",
    "- DataCollatorForSeq2Seq handles variable-length sequences with proper padding\n",
    "- No packing to preserve conversation structure\n",
    "- Single dataloader worker for ROCm stability\n",
    "- Gradient checkpointing via Unsloth for memory optimization\n",
    "\n",
    "The model is then trained on the 74 logical reasoning conversations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d05799dd-25f8-4a03-8bb0-6b91d5d6dda3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\ud83d\udcbe SAVING ROCM-TRAINED MODEL\n",
      "\u2705 LoRA adapters saved to: logical_reasoning_rocm_lora\n",
      "\ud83d\udd04 Saving merged model...\n",
      "Found HuggingFace hub cache directory: /root/.cache/huggingface/hub\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cc662bd182643d88ba24e303d4c42a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 1 files:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking cache directory for required files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Copying 30 files from cache to `logical_reasoning_rocm_merged`: 100% 30/30 [02:14<00:00,  4.48s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully copied all 30 files from cache to `logical_reasoning_rocm_merged`\n",
      "Checking cache directory for required files...\n",
      "Cache check failed: tokenizer.model not found in local cache.\n",
      "Not all required files found in cache. Will proceed with downloading.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Preparing safetensor model files: 100% 30/30 [00:00<00:00, 466033.78it/s]\n",
      "Unsloth: Merging weights into 16bit: 100% 30/30 [03:32<00:00,  7.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Merge process complete. Saved to `/app/projects/Unsloth-AMD-Fine-Tuning-Synthetic-Data/logical_reasoning/logical_reasoning_rocm_merged`\n",
      "\u2705 Merged model saved to: logical_reasoning_rocm_merged\n",
      "\n",
      "\ud83c\udf89 ROCM MODEL READY!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Save the trained model\"\"\"\n",
    "print(\"\\n\ud83d\udcbe SAVING ROCM-TRAINED MODEL\")\n",
    "\n",
    "# Save LoRA adapters\n",
    "lora_path = \"logical_reasoning_rocm_lora\"\n",
    "model.save_pretrained(lora_path)\n",
    "tokenizer.save_pretrained(lora_path)\n",
    "print(f\"\u2705 LoRA adapters saved to: {lora_path}\")\n",
    "\n",
    "# Save merged model\n",
    "merged_path = \"logical_reasoning_rocm_merged\"\n",
    "print(\"\ud83d\udd04 Saving merged model...\")\n",
    "model.save_pretrained_merged(merged_path, tokenizer, save_method=\"merged_16bit\")\n",
    "print(f\"\u2705 Merged model saved to: {merged_path}\")\n",
    "\n",
    "print(f\"\\n\ud83c\udf89 ROCM MODEL READY!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zlv8ydhyokk",
   "metadata": {},
   "source": [
    "### Saving the Fine-Tuned Model\n",
    "\n",
    "This cell saves the trained model in two formats:\n",
    "\n",
    "1. **LoRA Adapters** (`logical_reasoning_rocm_lora/`):\n",
    "   - Saves only the trained LoRA adapter weights (lightweight, ~few hundred MB)\n",
    "   - Can be loaded later with the base model\n",
    "   - Useful for sharing or deploying with the original base model\n",
    "\n",
    "2. **Merged Model** (`logical_reasoning_rocm_merged/`):\n",
    "   - Merges LoRA adapters back into the base model\n",
    "   - Creates a standalone model with all weights\n",
    "   - Saved in 16-bit precision for better quality\n",
    "   - Ready for immediate inference without loading adapters\n",
    "\n",
    "Both formats include the tokenizer configuration. The merged model is production-ready and can be used directly for generating answers to logical reasoning questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f9b5d9-a31e-4824-80e4-26b75e68d401",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97406d4-568e-40b7-84b5-6066d58a8d86",
   "metadata": {},
   "source": [
    "### Testing the model after creating it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0f52e33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#asfd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "771890fd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inference_test_cell",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Test the fine-tuned model with inference\"\"\"\n",
    "# Switch model to inference mode\n",
    "FastLanguageModel.for_inference(model)\n",
    "\n",
    "# Test question - a classic knight/knave logic puzzle\n",
    "test_question = \"A says 'B is a knave.' B says 'A and I are different types.' What are A and B?\"\n",
    "\n",
    "# Format the prompt using the chat template\n",
    "messages = [{\"role\": \"user\", \"content\": test_question}]\n",
    "input_text = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    tokenize=False, \n",
    "    add_generation_prompt=True  # Adds assistant header so model knows to respond\n",
    ")\n",
    "\n",
    "# Tokenize and move to GPU\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "# Generate response\n",
    "outputs = model.generate(\n",
    "    **inputs,\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.1,      # Low temperature for more deterministic logical reasoning\n",
    "    top_p=0.9,\n",
    "    do_sample=True,\n",
    "    pad_token_id=tokenizer.pad_token_id,\n",
    ")\n",
    "\n",
    "# Decode only the generated part (exclude the input prompt)\n",
    "response = tokenizer.decode(outputs[0][inputs['input_ids'].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "print(f\"Question: {test_question}\\n\")\n",
    "print(f\"Answer: {response}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (vLLM Container)",
   "language": "python",
   "name": "vllm-container"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}